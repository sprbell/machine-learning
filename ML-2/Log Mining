 #import pyspark
import re
from pyspark.sql import SparkSession
from pyspark.sql.functions import regexp_extract,last,desc
import matplotlib.pyplot as plt

spark = SparkSession.builder \
    .master("local[2]") \
    .appName("COM6012 Assignment 1") \
    .getOrCreate()

sc = spark.sparkContext
sc.setLogLevel("WARN") 

#******************************************************************************************************
# Q1 A find out requests base on four-hour slot
# Load file
logFile=spark.read.text("./Data/NASA_access_log_Jul95.gz").cache() #count 1891715
# create list for storing results
time_num_list=[]

# 1
# Select diferent time slot data by using regular expressions
logfile_time1=logFile.select(regexp_extract('value',r'1995:0[0-3]:[0-9]{2}',0).alias('timestamp'))
# Remove blank rows from selected data
time1_num=logfile_time1.filter(logfile_time1.timestamp.contains("1995")).count()
# Calculate the average number and add to list
time_num_list.append(time1_num/28)
# 2
logfile_time2=logFile.select(regexp_extract('value',r'1995:0[4-7]:[0-9]{2}',0).alias('timestamp'))
time2_num=logfile_time2.filter(logfile_time2.timestamp.contains("1995")).count()
time_num_list.append(time2_num/28)
# 3
logfile_time3=logFile.select(regexp_extract('value',r'1995:(08|09|10|11):[0-9]{2}',0).alias('timestamp'))
time3_num=logfile_time3.filter(logfile_time3.timestamp.contains("1995" )).count()
time_num_list.append(time3_num/28)
# 4
logfile_time4=logFile.select(regexp_extract('value',r'1995:1[2-5]:[0-9]{2}',0).alias('timestamp'))
time4_num=logfile_time4.filter(logfile_time4.timestamp.contains("1995")).count()
time_num_list.append(time4_num/28)
# 5
logfile_time5=logFile.select(regexp_extract('value',r'1995:1[6-9]:[0-9]{2}',0).alias('timestamp'))
time5_num=logfile_time5.filter(logfile_time5.timestamp.contains("1995")).count()
time_num_list.append(time5_num/28)
# 6
logfile_time6=logFile.select(regexp_extract('value',r'1995:2[0-3]:[0-9]{2}',0).alias('timestamp'))
time6_num=logfile_time6.filter(logfile_time6.timestamp.contains("1995")).count()
time_num_list.append(time6_num/28)

# Write the result to a output .txt file
file1 = open("Q1A_output.txt",'w')
for i in range(len(time_num_list)):
	file1.write('Slot {0}:'.format(i+1))
	file1.write(str(time_num_list[i])+'\n')

#******************************************************************************************************
# Q1 B Visualise the results in A
plt.bar(range(len(time_num_list)), time_num_list,fc='b')
plt.xlabel("Hour slot")
plt.ylabel("Average number")
plt.title("Average number of requests on each four hours of a day")
plt.xticks(range(6), ['00-03','04-07','08-11','12-15','16-19','20-23'])
# Add value to bar chart
x=range(6)
y=time_num_list
for a,b in zip(x,y):
    plt.text(a,b+0.1,'%.0f'%b,ha = 'center',va = 'bottom',fontsize=11)
plt.show()
plt.savefig("Q1B_barchart.png")

#******************************************************************************************************
#Q1 C Find out the top 20 most requested .html files

# Extract html data by using regular expressions
host_all=logFile.select(regexp_extract('value',r'/[\w_-]+.html',0).alias('hostname'))
host_name=host_all.filter(host_all.hostname.contains("html"))
# Count and arrange from big to small, choose the top 20
top_20_host=host_name.groupby('hostname').count().sort(desc('count')).limit(20)
host_list=top_20_host.collect()
#add result to list
host_name_list=[]
host_count_list=[]
for i in range(len(host_list)):
    host_name_list.append(host_list[i][0])
    host_count_list.append(host_list[i][1])

# Write the result to a output .txt file
file2 = open("Q1C_output.txt",'w')
for i in range(len(host_name_list)):
	file2.write('file name:{0} count:{1}'.format(host_name_list[i],host_count_list[i]))
	file2.write('\n')

#******************************************************************************************************
# Q1 D Visualise the results in C
plt.figure(figsize=(10,10)) 
labels = host_name_list 
sizes = host_count_list 
colors=['r','orange','b','greenyellow', 'g','c', 'm', 'yellow', 'navy']
patches,text1,text2 = plt.pie(sizes,labels=labels,  
                              colors=colors,  
                              autopct = '%3.2f%%',
                              shadow = False,  
                              startangle =30,  
                              pctdistance = 1.1, 
                              labeldistance=1.2)

plt.title(" Top 20 most requested .html files")
plt.show()
plt.savefig("Q1D_piechart.png")
spark.stop()
