# import the library all the time  XD GL
import time
from pyspark.sql import SparkSession
import pyspark.sql.functions as fn
from pyspark.ml import Pipeline
from pyspark.ml.feature import StringIndexer, VectorAssembler,IndexToString
from pyspark.sql.functions import split,regexp_extract
from pyspark.sql.types import DecimalType,IntegerType,DoubleType
from pyspark.ml.tuning import CrossValidator, ParamGridBuilder
from pyspark.ml.classification import RandomForestClassifier
from pyspark.ml.classification import GBTClassifier
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.ml.regression import LinearRegression
from pyspark.ml.evaluation import RegressionEvaluator

# Create the spark session
spark = SparkSession \
        .builder.master("local[4]")\
        .appName("SML_Assignment2")\
        .config("spark.local.dir","/fastdata/acp19cj") \
        .getOrCreate()

sc = spark.sparkContext
sc.setLogLevel("WARN")
# Escape from the notation
File = spark.read.csv("./train_set.csv",header = True).cache()

# Obtain the columns' name 
col_names = File.columns
# Firstly we should replace the symbol '?' with None to filter the missing value row
raw_data = File.replace("?",None)
# Then we should filter the dataframe with the isNotNull() function
for i in range(len(col_names)):
    raw_data = raw_data.filter(raw_data[col_names[i]].isNotNull())
# We have obtain all the raw_data without the missing value
# We don't need the Row_ID and Household_ID for traning so we delete these two columns
raw_data = raw_data.drop(raw_data[col_names[0]])
raw_data = raw_data.drop(raw_data[col_names[1]])

# Use the Assembler and StringIndexer to conver the featires into the data structure we want
# The range of the columns we need to change is from Blind_Make to Cat12 as the single feature. 
# We could use the all the features except the first two column feature
for i in range(17):
    labelIndexer = StringIndexer(inputCol=col_names[i+2], outputCol= col_names[i+2]+"_Indexer").fit(raw_data)
    raw_data = labelIndexer.transform(raw_data)

labelIndexer = StringIndexer(inputCol="NVCat", outputCol= "NVCat_Indexer").fit(raw_data)
raw_data = labelIndexer.transform(raw_data)

# Obtain the after change features' columns
col_name = raw_data.columns
feature_name = col_name[32:]+col_names[20:29]+col_names[30:34]
raw_dataset = raw_data.select(feature_name)

# Use the Aeembler function to generate the feature vector
col_names = raw_dataset.columns
for i in range(len(col_names)):
    raw_dataset = raw_dataset.withColumn(col_names[i],raw_dataset[col_names[i]].cast(DoubleType()))
assembler = VectorAssembler(inputCols=col_names[1:], outputCol="features")
train_data = assembler.transform(raw_dataset)
train_data = train_data.withColumnRenamed('Claim_Amount','Amount')
train_data = train_data.select("Amount","features")

# Now we should applu the Regression Model
# The way to handle with the inbalanced data set is use the remain
# Obtain the size of train set without None value
size_dataset = train_data.count()
num_negatives = train_data.filter(train_data.Amount==0).count()
balance_Ratio = (size_dataset - num_negatives)/size_dataset
weight_matrix = fn.udf(lambda rdd:(1-balance_Ratio) if rdd==0 else balance_Ratio,DoubleType())
# Now we could obtain the WeightMatix about the label 
train_data = train_data.withColumn("weights",weight_matrix(train_data.Amount))

# Now we have process the inbalanced dataset with the weight matrix

# Now we should create the LogressionModel Firstly we split the full dataset into train and test set
# We need to pick out the vectors which has the amount and which have negative value
data_neg = train_data.filter(train_data.Amount==0)
data_amount = train_data.filter(train_data.Amount!=0)
(scalable_negdata,remain_negdata) = data_neg.randomSplit([0.7,0.3],23)
(scalable_data, remain_data) = data_amount.randomSplit([0.7,0.3],23)
train = scalable_negdata.union(scalable_data)
test = remain_negdata.union(remain_data)

# Train the model
lr_model = LinearRegression(maxIter=10, labelCol='Amount',featuresCol='features',weightCol='weights',regParam=0.8, elasticNetParam=1)
start_time = time.mktime(time.localtime())
model = lr_model.fit(train)
end_time = time.mktime(time.localtime())
prediction = model.transform(test)
evaluator_mae = RegressionEvaluator\
      (predictionCol='prediction', labelCol='Amount', metricName='mae')
evaluator_mse = RegressionEvaluator\
      (predictionCol='prediction', labelCol='Amount', metricName='mse')
MAE = evaluator_mae.evaluate(prediction)
MSE = evaluator_mse.evaluate(prediction)
result_file = open("./result_Q2.txt","w")
result_file.write("Linear Model MAE:"+str(MAE)+"\n")
result_file.write("Linear Model MSE:"+str(MSE)+"\n")
result_file.write("LinearRegression Time:"+str((end_time-start_time)/60)+"\n")
result_file.write("\n")
result_file.write("\n")


# 3b
# Now We should Imply the Binary Classfier Model named LogisticRegression
lg = LogisticRegression\
        (featuresCol='features', labelCol='label_binary', weightCol="weights", regParam=0.0, elasticNetParam=1,family="auto")
start_time = time.mktime(time.localtime())
lg_model = lg.fit(train)
end_time = time.mktime(time.localtime())
prediction = lg_model.transform(test)
evaluator_roc = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', labelCol='label_binary', metricName='areaUnderROC')
auc = evaluator_roc.evaluate(prediction)
result_file.write("LogisticRegression AUC:"+str(auc)+"\n")
result_file.write("LogisticRegression Time:"+str((end_time-start_time)/60)+"\n")
result_file.write("\n")
result_file.write("\n")

# Now we should imply the GML model 
# Firstly we should choose the prediction valued 1's data and put them into the train model
train_GR = prediction.filter(prediction.prediction==1)
# Select Model
model_GR = GeneralizedLinearRegression(family="gamma", link="inverse", weightCol="weights", labelCol="Amount", maxIter=10, regParam=0.3)
start_time = time.mktime(time.localtime())
GR = model_GR.fit(train_GR)
end_time = time.mktime(time.localtime())
# Transform the data
prediction_GR = GR.transform(test)
# Obtain the Evaluator parameters
MAE_GR = evaluator_mae.evaluate(prediction_GR)
MSE_GR = evaluator_mse.evaluate(prediction_GR)
result_file.write("GeneralizedLinearRegression MAE:"+str(MAE_GR)+"\n")
result_file.write("GeneralizedLinearRegression MSE:"+str(MSE_GR)+"\n")
result_file.write("LinearRegression Time:"+str((end_time-start_time)/60)+"\n")
result_file.write("\n")
result_file.write("\n")

result_file.close()
